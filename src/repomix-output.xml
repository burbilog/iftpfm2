This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
cli.rs
config.rs
ftp_ops.rs
instance.rs
lib.rs
logging.rs
main.rs
shutdown.rs
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="cli.rs">
use std::env;
use std::process;

/// Prints usage instructions for the program.
///
/// Uses `PROGRAM_NAME` constant from `crate` for the executable name.
pub fn print_usage() {
    println!(
        "Usage: {} [-h] [-v] [-d] [-r] [-l logfile] [-p parallel] [-g grace_seconds] config_file",
        crate::PROGRAM_NAME // Now using PROGRAM_NAME from lib.rs
    );
}

/// Parses command line arguments and returns configuration options
///
/// # Returns
/// A tuple containing:
/// - `bool`: Whether to delete source files after transfer
/// - `Option<String>`: Path to log file (None for stdout).
/// - `Option<String>`: Path to config file.
/// - `usize`: Number of parallel threads.
/// - `bool`: Whether to randomize processing order.
/// - `u64`: Grace period in seconds for shutdown.
///
/// # Panics
/// - If required arguments are missing
/// - If numeric arguments can't be parsed
///
/// # Example
/// ```
/// // let (delete, log_file, config_file, parallel, randomize, grace_seconds) = parse_args();
/// ```
pub fn parse_args() -> (bool, Option<String>, Option<String>, usize, bool, u64) {
    let mut log_file = None;
    let mut delete = false;
    let mut config_file = None;
    let mut parallel = 1;
    let mut randomize = false;
    let mut grace_seconds = 30; // Default grace period

    let mut args = env::args();
    args.next(); // Skip program name

    while let Some(arg) = args.next() {
        match arg.as_str() {
            "-h" => {
                print_usage();
                process::exit(0);
            }
            "-v" => {
                println!("{} version {}", crate::PROGRAM_NAME, crate::PROGRAM_VERSION); // Using constants from lib.rs
                process::exit(0);
            }
            "-d" => delete = true,
            "-l" => log_file = Some(args.next().expect("Missing log file argument")),
            "-p" => {
                parallel = args
                    .next()
                    .expect("Missing parallel count argument")
                    .parse()
                    .expect("Parallel count must be a number")
            }
            "-r" => randomize = true,
            "-g" => {
                grace_seconds = args
                    .next()
                    .expect("Missing grace seconds argument")
                    .parse()
                    .expect("Grace seconds must be a number")
            }
            _ => {
                if config_file.is_none() {
                    config_file = Some(arg);
                } else {
                    eprintln!("Unexpected argument: {}", arg);
                    print_usage();
                    process::exit(1);
                }
            }
        }
    }

    if config_file.is_none() {
        eprintln!("Missing config file argument");
        print_usage();
        process::exit(1);
    }

    (delete, log_file, config_file, parallel, randomize, grace_seconds)
}
</file>

<file path="config.rs">
use regex::Regex;
use std::fs::File;
use std::io::{BufRead, BufReader, Error, ErrorKind}; // Removed 'self'
use std::str::FromStr;

/// FTP transfer configuration parameters
#[derive(Debug, PartialEq)]
pub struct Config {
    /// Source FTP server IP/hostname
    pub ip_address_from: String,
    /// Source FTP server port (typically 21)
    pub port_from: u16,
    /// Username for source FTP server
    pub login_from: String,
    /// Password for source FTP server
    pub password_from: String,
    /// Source directory path (must be literal path, no wildcards)
    pub path_from: String,
    /// Destination FTP server IP/hostname
    pub ip_address_to: String,
    /// Destination FTP server port (typically 21)
    pub port_to: u16,
    /// Username for destination FTP server
    pub login_to: String,
    /// Password for destination FTP server
    pub password_to: String,
    /// Destination directory path
    pub path_to: String,
    /// Minimum file age to transfer (seconds)
    pub age: u64,
    /// Regular expression pattern for filename matching
    pub filename_regexp: String,
}

/// Parses configuration file into a vector of Config structs
///
/// # Arguments
/// * `filename` - Path to configuration file
///
/// # Returns
/// * `Result<Vec<Config>, Error>` - Vector of parsed configs or error
///
/// # Errors
/// - File not found or unreadable
/// - Invalid field format (non-numeric where expected)
/// - Missing required fields
///
/// # File Format
/// CSV format with fields:
/// ip_from,port_from,login_from,password_from,path_from,
/// ip_to,port_to,login_to,password_to,path_to,min_age_secs
///
/// # Example
/// ```
/// // let configs = parse_config("settings.csv")?;
/// ```
pub fn parse_config(filename: &str) -> Result<Vec<Config>, Error> {
    let file = File::open(filename)?;
    let reader = BufReader::new(file);

    let mut configs = Vec::new();
    for line in reader.lines() {
        let line = line?;
        if line.starts_with('#') || line.trim().is_empty() {
            continue;
        }

        let mut fields = line.split(',');
        let host_from = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: host_from",
            ))?
            .to_string();
        let port_from = u16::from_str(fields.next().ok_or(Error::new(
            ErrorKind::InvalidInput,
            "missing field: port_from",
        ))?)
        .map_err(|e| Error::new(ErrorKind::InvalidInput, e))?;
        let user_from = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: user_from",
            ))?
            .to_string();
        let pass_from = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: pass_from",
            ))?
            .to_string();
        let path_from = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: path_from",
            ))?
            .to_string();
        let host_to = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: host_to",
            ))?
            .to_string();
        let port_to = u16::from_str(fields.next().ok_or(Error::new(
            ErrorKind::InvalidInput,
            "missing field: port_to",
        ))?)
        .map_err(|e| Error::new(ErrorKind::InvalidInput, e))?;
        let user_to = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: user_to",
            ))?
            .to_string();
        let pass_to = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: pass_to",
            ))?
            .to_string();
        let path_to = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: path_to",
            ))?
            .to_string();
        let age = u64::from_str(
            fields
                .next()
                .ok_or(Error::new(ErrorKind::InvalidInput, "missing field: age"))?,
        )
        .map_err(|e| Error::new(ErrorKind::InvalidInput, e))?;

        let filename_regexp = fields
            .next()
            .ok_or(Error::new(
                ErrorKind::InvalidInput,
                "missing field: filename_regexp",
            ))?
            .to_string();

        // Validate the regex pattern
        Regex::new(&filename_regexp).map_err(|e| {
            Error::new(
                ErrorKind::InvalidInput,
                format!("invalid filename regex pattern: {}", e),
            )
        })?;

        configs.push(Config {
            ip_address_from: host_from,
            port_from,
            login_from: user_from,
            password_from: pass_from,
            path_from,
            ip_address_to: host_to,
            port_to,
            login_to: user_to,
            password_to: pass_to,
            path_to,
            age,
            filename_regexp,
        });
    }

    Ok(configs)
}

#[cfg(test)]
mod tests {
    use super::*; // Imports Config and parse_config from the outer module
    use std::fs::File;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::tempdir;

    #[test]
    fn test_parse_config() {
        let config_string = "192.168.0.1,22,user1,password1,/path/to/files/*,192.168.0.2,22,user2,password2,/path/to/files2,30,.*\n192.168.0.3,22,user3,password3,/path/to/files3/*,192.168.0.4,22,user4,password4,/path/to/files4,60,.*";
        let expected = vec![
            Config {
                ip_address_from: "192.168.0.1".to_string(),
                port_from: 22,
                login_from: "user1".to_string(),
                password_from: "password1".to_string(),
                path_from: "/path/to/files/*".to_string(),
                ip_address_to: "192.168.0.2".to_string(),
                port_to: 22,
                login_to: "user2".to_string(),
                password_to: "password2".to_string(),
                path_to: "/path/to/files2".to_string(),
                age: 30,
                filename_regexp: ".*".to_string(),
            },
            Config {
                ip_address_from: "192.168.0.3".to_string(),
                port_from: 22,
                login_from: "user3".to_string(),
                password_from: "password3".to_string(),
                path_from: "/path/to/files3/*".to_string(),
                ip_address_to: "192.168.0.4".to_string(),
                port_to: 22,
                login_to: "user4".to_string(),
                password_to: "password4".to_string(),
                path_to: "/path/to/files4".to_string(),
                age: 60,
                filename_regexp: ".*".to_string(),
            },
        ];

        let dir = tempdir().unwrap();
        let mut config_path = PathBuf::from(dir.path());
        config_path.push("config.csv");

        let mut file = File::create(&config_path).unwrap();
        file.write_all(config_string.as_bytes()).unwrap();

        let configs = parse_config(config_path.to_str().unwrap()).unwrap();
        assert_eq!(configs, expected);
    }
}
</file>

<file path="ftp_ops.rs">
use crate::config::Config;
use crate::logging::log_with_thread;
use crate::shutdown::is_shutdown_requested;
use ftp::FtpStream;
use regex::Regex;
use std::time::{Duration, SystemTime, UNIX_EPOCH}; // Moved Duration and UNIX_EPOCH here

/// Transfers files between FTP servers according to configuration
///
/// # Arguments
/// * `config` - FTP connection and transfer parameters
/// * `delete` - Whether to delete source files after transfer
/// * `thread_id` - Identifier for logging in parallel mode
///
/// # Returns
/// Number of files successfully transferred
///
/// # Errors
/// Logs errors but doesn't fail - returns count of successful transfers
///
/// # Behavior
/// - Skips files younger than config.age seconds
/// - Respects shutdown requests
/// - Logs detailed transfer progress
///
/// # Example
/// ```
/// // let count = transfer_files(&config, true, 1);
/// ```
pub fn transfer_files(config: &Config, delete: bool, thread_id: usize) -> i32 {
    // Check for shutdown request before starting
    if is_shutdown_requested() {
        log_with_thread("Shutdown requested, skipping transfer", Some(thread_id)).unwrap();
        return 0;
    }

    log_with_thread(format!(
        "Transferring files from ftp://{}:{}{} to ftp://{}:{}{}",
        config.ip_address_from,
        config.port_from,
        config.path_from,
        config.ip_address_to,
        config.port_to,
        config.path_to
    )
    .as_str(), Some(thread_id))
    .unwrap();
    // Connect to the source FTP server
    let mut ftp_from = match FtpStream::connect((config.ip_address_from.as_str(), config.port_from))
    {
        Ok(ftp) => ftp,
        Err(e) => {
            log_with_thread(format!(
                "Error connecting to SOURCE FTP server {}: {}",
                config.ip_address_from, e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            return 0;
        }
    };
    ftp_from
        .login(config.login_from.as_str(), config.password_from.as_str())
        .unwrap_or_else(|e| {
            log_with_thread(format!(
                "Error logging into SOURCE FTP server {}: {}",
                config.ip_address_from, e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            // This return should be handled better, perhaps by propagating the error.
            // For now, matching original behavior of logging and returning.
        });
    match ftp_from.cwd(config.path_from.as_str()) {
        Ok(_) => (),
        Err(e) => {
            log_with_thread(format!(
                "Error changing directory on SOURCE FTP server {}: {}",
                config.ip_address_from, e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            return 0;
        }
    }

    // Connect to the target FTP server
    let mut ftp_to = match FtpStream::connect((config.ip_address_to.as_str(), config.port_to)) {
        Ok(ftp) => ftp,
        Err(e) => {
            log_with_thread(format!(
                "Error connecting to TARGET FTP server {}: {}",
                config.ip_address_to, e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            return 0;
        }
    };
    ftp_to
        .login(config.login_to.as_str(), config.password_to.as_str())
        .unwrap_or_else(|e| {
            log_with_thread(format!(
                "Error logging into TARGET FTP server {}: {}",
                config.ip_address_to, e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            // Similar to above, error handling could be improved.
        });
    match ftp_to.cwd(config.path_to.as_str()) {
        Ok(_) => (),
        Err(e) => {
            log_with_thread(format!(
                "Error changing directory on TARGET FTP server {}: {}",
                config.ip_address_to, e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            return 0;
        }
    }

    // Get the list of files in the source directory
    let file_list = match ftp_from.nlst(None) {
        Ok(list) => list,
        Err(e) => {
            log_with_thread(format!("Error getting file list from SOURCE FTP server: {}", e).as_str(), Some(thread_id)).unwrap();
            return 0;
        }
    };
    let number_of_files = file_list.len();
    log_with_thread(format!(
        "Number of files retrieved from SOURCE FTP server: {}",
        file_list.len()
    )
    .as_str(), Some(thread_id))
    .unwrap();
    let regex = match Regex::new(&config.filename_regexp) {
        Ok(re) => re,
        Err(e) => {
            log_with_thread(
                &format!("Invalid filename regex pattern '{}': {}", config.filename_regexp, e),
                Some(thread_id),
            ).unwrap();
            return 0;
        }
    };

    let mut successful_transfers = 0;
    for filename in file_list {
        if is_shutdown_requested() {
            log_with_thread("Shutdown requested, aborting remaining transfers", Some(thread_id)).unwrap();
            break;
        }

        if !regex.is_match(&filename) {
            log_with_thread(format!(
                "Skipping file {} as it did not match regex {}",
                filename, regex
            )
            .as_str(), Some(thread_id))
            .unwrap();
            continue;
        }

        // Get the modified time of the file on the FTP server.
        // ftp::FtpStream::mdtm returns Result<Option<ftp_chrono::DateTime<ftp_chrono::Utc>>>
        // Let type inference handle `datetime_utc_ftp_chrono`
        let datetime_utc_ftp_chrono = match ftp_from.mdtm(filename.as_str()) {
            Ok(Some(dt)) => dt, // dt is ftp_chrono::DateTime<Utc>
            Ok(None) => {
                log_with_thread(&format!(
                    "MDTM command not supported or file '{}' has no timestamp, skipping",
                    filename
                ), Some(thread_id))
                .unwrap();
                continue;
            }
            Err(e) => {
                log_with_thread(&format!(
                    "Error getting modified time for file '{}': {}, skipping",
                    filename,
                    e.to_string().replace("\n", "")
                ), Some(thread_id))
                .unwrap();
                continue;
            }
        };

        // Convert ftp_chrono::DateTime<Utc> to SystemTime for age calculation.
        // datetime_utc_ftp_chrono is from chrono 0.2.x via the ftp crate.
        let modified_system_time = {
            // Duration and UNIX_EPOCH are now imported at the top of the file.
            let secs = datetime_utc_ftp_chrono.timestamp();
            let nanos = datetime_utc_ftp_chrono.timestamp_subsec_nanos(); // This is u32 in chrono 0.2.x
            if secs < 0 {
                 // Handle pre-epoch times if necessary, though unlikely for FTP MDTM.
                 // For simplicity, we might log an error and skip, or use UNIX_EPOCH as a fallback.
                 // Here, we'll assume positive timestamps for typical FTP server file times.
                 // If secs is negative, UNIX_EPOCH + Duration::new(secs as u64, nanos) would panic.
                 // A more robust solution might involve conditional subtraction from UNIX_EPOCH.
                 // For now, let's proceed assuming MDTM gives times at or after epoch.
                 // If this assumption is wrong, this part needs more robust handling.
                log_with_thread(&format!(
                    "File '{}' has a pre-epoch modification time ({}), skipping",
                    filename, datetime_utc_ftp_chrono
                ), Some(thread_id)).unwrap();
                continue;
            }
            UNIX_EPOCH + Duration::new(secs as u64, nanos)
        };

        let file_age_seconds = match SystemTime::now().duration_since(modified_system_time) {
            Ok(duration) => duration.as_secs(),
            Err(_) => { // SystemTime::now() is earlier than modified_system_time (file from the future)
                log_with_thread(&format!(
                    "File '{}' has a modification time in the future ({} vs now), skipping",
                    filename, datetime_utc_ftp_chrono // Log the original ftp_chrono time
                ), Some(thread_id))
                .unwrap();
                continue;
            }
        };

        if file_age_seconds < config.age {
            log_with_thread(format!(
                "Skipping file {}, it is {} seconds old, less than specified age {} seconds",
                filename, file_age_seconds, config.age
            )
            .as_str(), Some(thread_id))
            .unwrap();
            continue;
        }

        match ftp_to.rm(filename.as_str()) {
            Ok(_) => {
                log_with_thread(format!("Deleted file {} at TARGET FTP server", filename).as_str(), Some(thread_id)).unwrap()
            }
            Err(_) => (), // Ignore error if file doesn't exist
        };

        if let Err(e) = ftp_from.transfer_type(ftp::types::FileType::Binary) {
            log_with_thread(format!(
                "Error setting binary mode on SOURCE FTP server: {}",
                e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            continue;
        }

        if let Err(e) = ftp_to.transfer_type(ftp::types::FileType::Binary) {
            log_with_thread(format!(
                "Error setting binary mode on TARGET FTP server: {}",
                e
            )
            .as_str(), Some(thread_id))
            .unwrap();
            continue;
        }

        match ftp_from.simple_retr(filename.as_str()) {
            Ok(mut data) => match ftp_to.put(filename.as_str(), &mut data) {
                Ok(_) => {
                    log_with_thread(format!("Successful transfer of file {}", filename).as_str(), Some(thread_id)).unwrap();
                    successful_transfers += 1;
                }
                Err(e) => {
                    log_with_thread(format!(
                        "Error transferring file {} to TARGET FTP server: {}",
                        filename, e
                    )
                    .as_str(), Some(thread_id))
                    .unwrap();
                    continue;
                }
            },
            Err(e) => {
                log_with_thread(format!(
                    "Error transferring file {} from SOURCE FTP server: {}",
                    filename, e
                )
                .as_str(), Some(thread_id))
                .unwrap();
                continue;
            }
        }

        if delete {
            match ftp_from.rm(filename.as_str()) {
                Ok(_) => {
                    log_with_thread(format!("Deleted SOURCE file {}", filename).as_str(), Some(thread_id)).unwrap();
                }
                Err(e) => {
                    log_with_thread(format!("Error deleting SOURCE file {}: {}", filename, e).as_str(), Some(thread_id))
                        .unwrap();
                }
            }
        }
    }
    log_with_thread(format!(
        "Successfully transferred {} files out of {}",
        successful_transfers, number_of_files
    )
    .as_str(), Some(thread_id))
    .unwrap();
    successful_transfers
}
</file>

<file path="instance.rs">
use crate::logging::log;
use crate::shutdown::request_shutdown;

use std::fs::File;
use std::io::{self, Write, Read};
use std::os::unix::net::{UnixListener, UnixStream};
use std::process::Command;
use ctrlc;

// Signal the existing process to terminate gracefully
fn signal_process_to_terminate(socket_path: &str, grace_seconds: u64) -> io::Result<()> {
    // Use lsof to find process using the socket
    let output = Command::new("lsof")
        .arg("-t")  // Output only PID
        .arg(socket_path)
        .output()?;

    if !output.status.success() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "Failed to find process using lsof"
        ));
    }

    let pid_str = String::from_utf8_lossy(&output.stdout).trim().to_string();
    if pid_str.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::NotFound,
            "No process found using the socket"
        ));
    }

    log(&format!("Found old instance with PID {}, sending termination signal", pid_str)).unwrap();

    // Set the shutdown flag for our own process if we're signaling ourselves
    // This case should ideally not happen if check_single_instance is called correctly,
    // but it's a safeguard.
    let our_pid = std::process::id().to_string();
    if pid_str == our_pid {
        request_shutdown();
        return Ok(());
    }

    // Send SIGTERM to allow graceful shutdown
    let term_output = Command::new("kill")
        .arg("-15")  // SIGTERM for graceful termination
        .arg(&pid_str)
        .output()?;

    if !term_output.status.success() {
        let stderr = String::from_utf8_lossy(&term_output.stderr);
        return Err(io::Error::new(
            io::ErrorKind::Other,
            format!("Failed to send termination signal to process {}: {}", pid_str, stderr)
        ));
    }

    log(&format!("Successfully sent termination signal to old instance with PID {}", pid_str)).unwrap();

    // Wait for up to grace_seconds for the process to terminate
    for i in 1..=(grace_seconds * 2) { // Check twice per second
        std::thread::sleep(std::time::Duration::from_millis(500));

        // Check if the process is still running
        let check_output = Command::new("kill")
            .arg("-0")  // Check if process exists
            .arg(&pid_str)
            .output()?;

        if !check_output.status.success() {
            log(&format!("Old instance with PID {} has terminated gracefully", pid_str)).unwrap();
            return Ok(());
        }

        if i % 2 == 0 { // Log every second
            log(&format!("Waiting for old instance with PID {} to terminate ({} of {} seconds)...",
                pid_str, i/2, grace_seconds)).unwrap();
        }
    }

    // If process didn't terminate after timeout, use SIGKILL as last resort
    log(&format!("Old instance with PID {} did not terminate gracefully, forcing termination", pid_str)).unwrap();
    let kill_output = Command::new("kill")
        .arg("-9")  // SIGKILL for forced termination
        .arg(&pid_str)
        .output()?;

    if !kill_output.status.success() {
        let stderr = String::from_utf8_lossy(&kill_output.stderr);
        return Err(io::Error::new(
            io::ErrorKind::Other,
            format!("Failed to force termination of process {}: {}", pid_str, stderr)
        ));
    }

    log(&format!("Forcibly terminated old instance with PID {}", pid_str)).unwrap();
    std::thread::sleep(std::time::Duration::from_millis(500)); // Give OS a moment

    Ok(())
}

/// Ensures only one instance runs at a time
///
/// # Behavior
/// - Creates lock file with PID
/// - Listens on Unix socket for shutdown requests
/// - Handles cleanup on exit
///
/// # Errors
/// - If socket creation fails
/// - If PID file can't be written
///
/// # Panics
/// If signal handler registration fails
pub fn check_single_instance(grace_seconds: u64) -> io::Result<()> {
    let socket_path = format!("/tmp/{}.sock", crate::PROGRAM_NAME); // Using PROGRAM_NAME from lib.rs

    // Try to connect to existing socket
    if UnixStream::connect(&socket_path).is_ok() {
        log(&format!("Another instance is running, new instance PID {} requesting graceful termination of old one.",
            std::process::id())).unwrap();

        // Try to signal the process to terminate gracefully
        if let Err(e) = signal_process_to_terminate(&socket_path, grace_seconds) {
            log(&format!("Failed to signal old process: {}. Stale socket/pid files might exist.", e)).unwrap();
            // Even if signaling fails, we might be able to remove the socket if it's stale.
        }

        // Attempt to clean up the socket file after signaling (or if signaling failed but socket was stale)
        // This is important so the new instance can bind to it.
        let _ = std::fs::remove_file(&socket_path);
        log(&format!("Removed old socket file: {}", socket_path)).unwrap();

    } else {
        // If connection failed, it might be because the socket file is stale (no one listening).
        // Clean it up before trying to bind.
        let _ = std::fs::remove_file(&socket_path);
    }

    // Create a new socket file for this instance
    let listener = UnixListener::bind(&socket_path)?;
    log(&format!("Created new socket file: {}", socket_path)).unwrap();

    // Write our PID to a common PID file location
    let pid_path = format!("/tmp/{}.pid", crate::PROGRAM_NAME); // Using PROGRAM_NAME from lib.rs
    let mut pid_file = File::create(&pid_path)?;
    pid_file.write_all(std::process::id().to_string().as_bytes())?;
    log(&format!("Written current PID {} to {}", std::process::id(), pid_path)).unwrap();

    // Set up signal handler for SIGINT (Ctrl+C) and SIGTERM
    let current_pid = std::process::id();
    ctrlc::set_handler(move || {
        log(&format!("Received termination signal (Ctrl+C or SIGTERM), PID {} shutting down gracefully", current_pid)).unwrap();
        request_shutdown();
        // The cleanup_lock_file will be called via scopeguard in main.
        // Consider if additional cleanup is needed here or if it's robust enough.
    }).expect("Error setting signal handler");

    // Spawn a thread to listen on the socket for shutdown commands from new instances.
    std::thread::spawn(move || {
        for stream in listener.incoming() {
            match stream {
                Ok(mut stream) => {
                    let mut buffer = [0; 8]; // Expect "SHUTDOWN"
                    if let Ok(size) = stream.read(&mut buffer) {
                        if size == 8 && &buffer[..] == b"SHUTDOWN" {
                            log(&format!("Received 'SHUTDOWN' command on socket. PID {} initiating self-shutdown.",
                                std::process::id())).unwrap();
                            request_shutdown();
                            break; // Exit listener thread
                        }
                    }
                }
                Err(e) => {
                    log(&format!("Error accepting incoming connection on socket: {}", e)).unwrap();
                    // Depending on the error, might want to break or continue.
                    // For now, continue to try accepting more connections.
                }
            }
        }
        log("Socket listener thread exiting.").unwrap();
    });

    Ok(())
}

/// Cleans up single instance lock files
///
/// Removes:
/// - Unix domain socket (/tmp/{PROGRAM_NAME}.sock)
/// - PID file (/tmp/{PROGRAM_NAME}.pid)
///
/// Called automatically on program exit (e.g., via scopeguard in main)
pub fn cleanup_lock_file() {
    let socket_path = format!("/tmp/{}.sock", crate::PROGRAM_NAME); // Using PROGRAM_NAME from lib.rs
    let pid_path = format!("/tmp/{}.pid", crate::PROGRAM_NAME); // Using PROGRAM_NAME from lib.rs

    log(&format!("Cleaning up lock files: {} and {}", socket_path, pid_path)).unwrap();

    if let Err(e) = std::fs::remove_file(&socket_path) {
        if e.kind() != std::io::ErrorKind::NotFound {
            log(&format!("Failed to remove socket file {}: {}", socket_path, e)).unwrap();
        }
    }
    if let Err(e) = std::fs::remove_file(&pid_path) {
        if e.kind() != std::io::ErrorKind::NotFound {
            log(&format!("Failed to remove pid file {}: {}", pid_path, e)).unwrap();
        }
    }
}
</file>

<file path="lib.rs">
//! FTP File Mover Utility Library
//!
//! This library contains the core logic for the iftpfm2 utility,
//! including configuration parsing, FTP operations, logging,
//! command-line interface handling, shutdown signaling, and
//! single-instance management.

// Module declarations
pub mod cli;
pub mod config;
pub mod ftp_ops;
pub mod instance;
pub mod logging;
pub mod shutdown;

// Re-export key items for easy use by the binary (main.rs)
pub use cli::parse_args;
pub use config::{parse_config, Config};
pub use ftp_ops::transfer_files;
pub use instance::{check_single_instance, cleanup_lock_file};
pub use logging::{log, log_with_thread, set_log_file};
pub use shutdown::{is_shutdown_requested, request_shutdown}; // Added request_shutdown

/// Name of the program used for:
/// - Process identification
/// - Lock files (/tmp/{PROGRAM_NAME}.pid)
/// - Unix domain socket (/tmp/{PROGRAM_NAME}.sock)
pub const PROGRAM_NAME: &str = "iftpfm2";

/// Current version of the program (from Cargo.toml)
/// Follows semantic versioning (MAJOR.MINOR.PATCH)
pub const PROGRAM_VERSION: &str = "2.0.6";

// Dependencies that were in main.rs and are used by multiple modules,
// or are fundamental to the library's operation, can be listed here
// or within the specific modules that use them.
// For now, each module handles its own specific imports.
// Common ones like `std::io`, `std::process` are used directly in modules.
// External crates like `ftp`, `regex`, `chrono`, `once_cell`, `rayon`, `ctrlc`, `scopeguard`
// will need to be listed in Cargo.toml and then `use`d in the modules that need them.

// Example of how PROGRAM_NAME and PROGRAM_VERSION might be used from within a module if not passed:
// use crate::{PROGRAM_NAME, PROGRAM_VERSION};
// This is now handled by making them pub const in lib.rs and modules using `crate::PROGRAM_NAME`.

// The `main` function in `src/main.rs` will now primarily use items from this library crate.
// e.g. `use iftpfm2::config::parse_config;` or `use iftpfm2::*;`
//
// We'll need to ensure that all necessary `pub` keywords are used within each module
// for items that need to be accessed by other modules or by `main.rs` via this lib.rs.
// For example, `Config` struct in `config.rs` must be `pub struct Config`.
// Functions like `parse_config` must be `pub fn parse_config`.
// Statics like `LOG_FILE` in `logging.rs` must be `pub static LOG_FILE`.

// Note: The temporary const declarations for PROGRAM_NAME in cli.rs and instance.rs
// were removed, and those modules now use `crate::PROGRAM_NAME` as intended.
</file>

<file path="logging.rs">
use chrono::Local;
use once_cell::sync::Lazy;
use std::fs::OpenOptions; // Removed 'File'
use std::io::{self, Write};
use std::path::Path;
use std::sync::Mutex;

// LOG_FILE is a thread-safe, lazily initialized global variable
// It holds an Option<String> representing the path to the log file (if set)
// The Mutex ensures thread-safe access to this value
/// Global log file path protected by Mutex
///
/// Thread-safe storage for optional log file path.
/// When None, logs go to stdout.
pub static LOG_FILE: Lazy<Mutex<Option<String>>> = Lazy::new(|| Mutex::new(None));

/// Logs a message to either a file or stdout
///
/// This function takes a message as input and logs it with a timestamp.
/// If a log file has been set (using set_log_file), the message is appended to that file.
/// Otherwise, the message is printed to stdout.
///
/// # Arguments
///
/// * `message` - The message to be logged
///
/// # Returns
///
/// * `io::Result<()>` - Ok if the logging was successful, Err otherwise
/// Logs a message with timestamp to configured output
///
/// # Arguments
/// * `message` - The message to log
///
/// # Returns
/// * `io::Result<()>` - Ok on success, Err if writing fails
///
/// # Example
/// ```
/// // log("Starting transfer").unwrap();
/// ```
pub fn log(message: &str) -> io::Result<()> {
    log_with_thread(message, None)
}

/// Logs a message with timestamp and optional thread ID
///
/// Used when running in parallel mode to distinguish threads
///
/// # Arguments
/// * `message` - The message to log
/// * `thread_id` - Optional thread identifier
///
/// # Returns
/// * `io::Result<()>` - Ok on success, Err if writing fails
///
/// # Example
/// ```
/// // log_with_thread("Thread started", Some(1)).unwrap();
/// ```
pub fn log_with_thread(message: &str, thread_id: Option<usize>) -> io::Result<()> {
    // Generate a timestamp for the log message
    let timestamp = Local::now().format("%Y-%m-%d %H:%M:%S").to_string();
    let log_message = match thread_id {
        Some(tid) => format!("{} [T{}] {}\n", timestamp, tid, message),
        None => format!("{} {}\n", timestamp, message),
    };

    // Lock the mutex and check if a log file has been set
    match &*LOG_FILE.lock().unwrap() {
        Some(log_file) => {
            // If a log file is set, append the message to the file
            let mut file = OpenOptions::new()
                .create(true)
                .append(true)
                .open(log_file)?;
            file.write_all(log_message.as_bytes())?;
        }
        None => {
            // If no log file is set, print the message to stdout.
            // The original code used println!() with a message already ending in \n,
            // resulting in a double newline. Restoring that behavior.
            println!("{}", log_message);
        }
    }

    Ok(())
}

/// Sets the path for the log file
///
/// This function updates the global LOG_FILE variable with the provided path.
/// Subsequent calls to the log function will write to this file.
///
/// # Arguments
///
/// * `path` - A path-like object representing the location of the log file
pub fn set_log_file<P: AsRef<Path>>(path: P) {
    // Convert the path to a string and update the LOG_FILE
    let path_str = path.as_ref().to_str().expect("Path is not valid UTF-8");
    *LOG_FILE.lock().unwrap() = Some(path_str.to_string());
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::{self, remove_file};
    use tempfile::tempdir;

    #[test]
    fn test_log_to_file() {
        let dir = tempdir().unwrap();
        let log_file_path = dir.path().join("log.txt");

        set_log_file(&log_file_path);
        log("test message 1").unwrap();
        log_with_thread("test message 2", Some(1)).unwrap();

        let log_contents = fs::read_to_string(&log_file_path).unwrap();
        assert!(log_contents.contains("test message 1"));
        assert!(log_contents.contains("[T1] test message 2"));

        // Clean up
        remove_file(log_file_path).unwrap();
        // Reset LOG_FILE for other tests if any
        *LOG_FILE.lock().unwrap() = None;
    }

    #[test]
    fn test_log_to_stdout() {
        // This test is harder to verify automatically without capturing stdout.
        // For now, we'll just call it to ensure it doesn't panic.
        // Manual verification or a more sophisticated test setup would be needed.
        *LOG_FILE.lock().unwrap() = None; // Ensure logging to stdout
        log("test stdout message 1").unwrap();
        log_with_thread("test stdout message 2", Some(2)).unwrap();
        // If we reach here, it means no panic occurred.
    }
}
</file>

<file path="main.rs">
//! FTP File Mover Utility - Main Binary Crate
//!
//! This crate serves as the entry point for the iftpfm2 executable.
//! It utilizes the `iftpfm2_lib` crate for all core logic.

// Use the library crate. This assumes `iftpfm2_lib` is correctly named in Cargo.toml
// or that Cargo.toml defines `iftpfm2` as the library name.
// If the library name is the same as the package, it's just `use iftpfm2;`
// For clarity, let's assume the library will be refered to by the project name `iftpfm2`.
use iftpfm2::*; // Import all re-exported items from lib.rs

use std::sync::Arc; // Keep Arc for main's specific logic
use rayon::prelude::*; // Keep rayon for main's specific logic
use std::process; // For process::exit

// Removed most imports as they are now handled within the library modules.
// Kept imports that are directly used in the main function's logic,
// like Arc for config sharing and rayon for parallelism.

// All functions and structs previously defined here are now in their respective modules
// within the library (src/lib.rs and its submodules).

/// Main program entry point
///
/// # Behavior
/// 1. Parses command line arguments using `iftpfm2::cli::parse_args`.
/// 2. Sets up logging using `iftpfm2::logging::set_log_file` and `iftpfm2::logging::log`.
/// 3. Enforces single instance using `iftpfm2::instance::check_single_instance`.
/// 4. Reads configuration using `iftpfm2::config::parse_config`.
/// 5. Processes transfers in parallel using `iftpfm2::ftp_ops::transfer_files`.
/// 6. Handles graceful shutdown using `iftpfm2::shutdown::is_shutdown_requested`.
/// 7. Cleans up lock files using `iftpfm2::instance::cleanup_lock_file`.
///
/// # Exit Codes
/// - 0: Success
/// - 1: Error during initialization
fn main() {
    // Parse arguments first to setup logging
    // These functions are now part of the library, accessed via the use statement.
    let (delete, log_file_option, config_file_option, parallel, randomize, grace_seconds) =
        parse_args(); // from iftpfm2::cli

    if let Some(lf) = log_file_option {
        set_log_file(lf); // from iftpfm2::logging
    }

    // Check for single instance after logging is configured
    if let Err(e) = check_single_instance(grace_seconds) { // from iftpfm2::instance
        // Ensure log function is available. It should be from iftpfm2::logging.
        log(&format!("Error checking single instance: {}", e))
            .expect("Failed to write to log during single instance check failure");
        process::exit(1);
    }
    
    // Ensure lock file is removed on normal exit or panic
    // `cleanup_lock_file` is from `iftpfm2::instance`
    let _cleanup = scopeguard::guard((), |_| cleanup_lock_file());

    log(&format!("{} version {} started", PROGRAM_NAME, PROGRAM_VERSION).as_str()) // PROGRAM_NAME & VERSION from lib.rs
        .expect("Failed to write initial start message to log");

    // Parse config file
    let config_file_path = config_file_option.expect("Config file path should be present due to parse_args validation");
    let configs_vec = match parse_config(&config_file_path) { // from iftpfm2::config
        Ok(cfgs) => cfgs,
        Err(e) => {
            log(&format!("Error parsing config file '{}': {}", config_file_path, e))
                .expect("Failed to write config parsing error to log");
            process::exit(1);
        }
    };

    // Create thread pool with specified parallelism
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(parallel.max(1)) // Ensure at least 1 thread
        .build()
        .unwrap_or_else(|e| {
            log(&format!("Error creating thread pool: {}", e))
                .expect("Failed to write thread pool creation error to log");
            process::exit(1);
        });

    // Process configs in parallel (randomize order if requested)
    let mut configs_to_process = configs_vec;
    if randomize {
        use rand::seq::SliceRandom;
        use rand::thread_rng;
        configs_to_process.shuffle(&mut thread_rng());
    }
    let configs_arc = Arc::new(configs_to_process);
    let delete_arc = Arc::new(delete);

    let total_transfers: i32 = pool.install(|| {
        configs_arc
            .par_iter()
            .enumerate()
            .map(|(idx, cf_item)| { // cf_item is a reference to Config
                // Check for shutdown before starting each config
                if is_shutdown_requested() { // from iftpfm2::shutdown
                    return 0;
                }
                let thread_id = rayon::current_thread_index().unwrap_or(idx);
                // transfer_files is from iftpfm2::ftp_ops
                transfer_files(cf_item, *delete_arc, thread_id)
            })
            .sum()
    });

    let exit_message = if is_shutdown_requested() { // from iftpfm2::shutdown
        format!(
            "{} version {} terminated due to shutdown request, transferred {} file(s)",
            PROGRAM_NAME, PROGRAM_VERSION, total_transfers // Constants from lib.rs
        )
    } else {
        format!(
            "{} version {} finished, successfully transferred {} file(s)",
            PROGRAM_NAME, PROGRAM_VERSION, total_transfers // Constants from lib.rs
        )
    };
    
    log(&exit_message).expect("Failed to write final exit message to log");
}
</file>

<file path="shutdown.rs">
use std::sync::atomic::{AtomicBool, Ordering};

// Global flag to indicate if shutdown was requested
/// Global shutdown flag (atomic bool)
///
/// Set to true when shutdown is requested via signal.
/// Threads should check this flag regularly and exit cleanly.
pub static SHUTDOWN_REQUESTED: AtomicBool = AtomicBool::new(false);

// Check if shutdown was requested
/// Checks if graceful shutdown has been requested
///
/// Threads should call this regularly and exit cleanly if true
///
/// # Returns
/// `true` if shutdown was requested via signal
pub fn is_shutdown_requested() -> bool {
    SHUTDOWN_REQUESTED.load(Ordering::SeqCst)
}

// Signal that shutdown is requested
/// Signals all threads to shutdown gracefully
///
/// Sets global flag that threads should check via is_shutdown_requested()
pub fn request_shutdown() {
    SHUTDOWN_REQUESTED.store(true, Ordering::SeqCst);
}
</file>

</files>
